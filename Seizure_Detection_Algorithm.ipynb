{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naomifelleke/Seizure-Detection/blob/main/Seizure_Detection_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgxWWHTjUI0S",
        "outputId": "f4e0edee-e73e-4d5f-ddae-7c0fd57616c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Downloading Data"
      ],
      "metadata": {
        "id": "LLZanxCy2pOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUFZpR1ZVfBy"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AITRICS/EEG_real_time_seizure_detection.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKjlKtrpVg3z"
      },
      "outputs": [],
      "source": [
        "%cd EEG_real_time_seizure_detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkK4LvMhVjkG"
      },
      "outputs": [],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKJc99I0XSAq"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This will prompt you to upload files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-lbGjwHWeHO"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements\\ \\(1\\).txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "catGvlEyX2r3"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y libpython3-dev\n",
        "!pip install --upgrade pip\n",
        "!pip install --no-cache-dir pyedflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bciyC8qcYb89"
      },
      "outputs": [],
      "source": [
        "!pip install mne\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AyaHthHeXew"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/tuh_eeg_seizure.zip -d /content/tuh_eeg_seizure\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "3tGO6rUF2a6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjzLGkkai-h8"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Copyright (c) 2022, Kwanhyung Lee, AITRICS. All rights reserved.\n",
        "#\n",
        "# Licensed under the MIT License;\n",
        "# you may not use this file except in compliance with the License.\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "from pyedflib import highlevel, EdfReader\n",
        "from scipy.io.wavfile import write\n",
        "from scipy import signal as sci_sig\n",
        "from scipy.spatial.distance import pdist\n",
        "from scipy.signal import stft, hilbert, butter, freqz, filtfilt, find_peaks\n",
        "from builder.utils.process_util import run_multi_process\n",
        "from builder.utils.utils import search_walk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import glob\n",
        "import pickle\n",
        "import random\n",
        "import mne\n",
        "from mne.io.edf.edf import _read_annotations_edf, _read_edf_header\n",
        "from itertools import groupby\n",
        "\n",
        "GLOBAL_DATA = {}\n",
        "label_dict = {}\n",
        "sample_rate_dict = {}\n",
        "sev_label = {}\n",
        "\n",
        "\n",
        "def label_sampling_tuh(labels, feature_samplerate):\n",
        "    y_target = \"\"\n",
        "    remained = 0\n",
        "    feature_intv = 1/float(feature_samplerate)\n",
        "    for i in labels:\n",
        "        begin, end, label = i.split(\" \")[:3]\n",
        "\n",
        "        intv_count, remained = divmod(float(end) - float(begin) + remained, feature_intv)\n",
        "        y_target += int(intv_count) * str(GLOBAL_DATA['disease_labels'][label])\n",
        "    return y_target\n",
        "\n",
        "\n",
        "def generate_training_data_leadwise_tuh_train(file):\n",
        "    sample_rate = GLOBAL_DATA['sample_rate']    # EX) 200Hz\n",
        "    file_name = \".\".join(file.split(\".\")[:-1])  # EX) /content/tuh_eeg_seizuretrain/01_tcp_ar/072/00007235/s003_2010_11_20/00007235_s003_t000\n",
        "    data_file_name = file_name.split(\"/\")[-1]   # EX) 00007235_s003_t000\n",
        "    signals, signal_headers, header = highlevel.read_edf(file)\n",
        "    label_list_c = []\n",
        "    for idx, signal in enumerate(signals):\n",
        "        label_noref = signal_headers[idx]['label'].split(\"-\")[0]    # EX) EEG FP1-ref or EEG FP1-LE --> EEG FP1\n",
        "        label_list_c.append(label_noref)\n",
        "\n",
        "    ############################# part 1: labeling  ###############################\n",
        "    label_file = open(file_name + \".\" + GLOBAL_DATA['args.label_type'], 'r') # EX) 00007235_s003_t003.tse or 00007235_s003_t003.tse_bi\n",
        "    y = label_file.readlines()\n",
        "    y = list(y[2:])\n",
        "    y_labels = list(set([i.split(\" \")[2] for i in y]))\n",
        "    signal_sample_rate = int(signal_headers[0]['sample_rate'])\n",
        "    if sample_rate > signal_sample_rate:\n",
        "        return\n",
        "    if not all(elem in label_list_c for elem in GLOBAL_DATA['label_list']): # if one or more of ['EEG FP1', 'EEG FP2', ... doesn't exist\n",
        "        return\n",
        "    # if not any(elem in y_labels for elem in GLOBAL_DATA['disease_type']): # if non-patient exist\n",
        "    #     return\n",
        "    y_sampled = label_sampling_tuh(y, GLOBAL_DATA['feature_sample_rate'])\n",
        "\n",
        "    ############################# part 2: input data filtering #############################\n",
        "    signal_list = []\n",
        "    signal_label_list = []\n",
        "    signal_final_list_raw = []\n",
        "\n",
        "    for idx, signal in enumerate(signals):\n",
        "        label = signal_headers[idx]['label'].split(\"-\")[0]\n",
        "        if label not in GLOBAL_DATA['label_list']:\n",
        "            continue\n",
        "\n",
        "        if int(signal_headers[idx]['sample_rate']) > sample_rate:\n",
        "            secs = len(signal)/float(signal_sample_rate)\n",
        "            samps = int(secs*sample_rate)\n",
        "            x = sci_sig.resample(signal, samps)\n",
        "            signal_list.append(x)\n",
        "            signal_label_list.append(label)\n",
        "        else:\n",
        "            signal_list.append(signal)\n",
        "            signal_label_list.append(label)\n",
        "\n",
        "    if len(signal_label_list) != len(GLOBAL_DATA['label_list']):\n",
        "        print(\"Not enough labels: \", signal_label_list)\n",
        "        return\n",
        "\n",
        "    for lead_signal in GLOBAL_DATA['label_list']:\n",
        "        signal_final_list_raw.append(signal_list[signal_label_list.index(lead_signal)])\n",
        "\n",
        "    new_length = len(signal_final_list_raw[0]) * (float(GLOBAL_DATA['feature_sample_rate']) / GLOBAL_DATA['sample_rate'])\n",
        "\n",
        "    if len(y_sampled) > new_length:\n",
        "        y_sampled = y_sampled[:new_length]\n",
        "    elif len(y_sampled) < new_length:\n",
        "        diff = int(new_length - len(y_sampled))\n",
        "        y_sampled += y_sampled[-1] * diff\n",
        "\n",
        "    y_sampled_np = np.array(list(map(int,y_sampled)))\n",
        "    new_labels = []\n",
        "    new_labels_idxs = []\n",
        "\n",
        "    ############################# part 3: slicing for easy training  #############################\n",
        "    y_sampled = [\"0\" if l not in GLOBAL_DATA['selected_diseases'] else l for l in y_sampled]\n",
        "\n",
        "    if any(l in GLOBAL_DATA['selected_diseases'] for l in y_sampled):\n",
        "        y_sampled = [str(GLOBAL_DATA['target_dictionary'][int(l)]) if l in GLOBAL_DATA['selected_diseases'] else l for l in y_sampled]\n",
        "\n",
        "    # slice and save if training data\n",
        "    new_data = {}\n",
        "    raw_data = torch.Tensor(signal_final_list_raw).permute(1,0)\n",
        "\n",
        "    max_seg_len_before_seiz_label = GLOBAL_DATA['max_bckg_before_slicelength'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    max_seg_len_before_seiz_raw = GLOBAL_DATA['max_bckg_before_slicelength'] * GLOBAL_DATA['sample_rate']\n",
        "    max_seg_len_after_seiz_label = GLOBAL_DATA['max_bckg_after_seiz_length'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    max_seg_len_after_seiz_raw = GLOBAL_DATA['max_bckg_after_seiz_length'] * GLOBAL_DATA['sample_rate']\n",
        "\n",
        "    min_seg_len_label = GLOBAL_DATA['min_binary_slicelength'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    min_seg_len_raw = GLOBAL_DATA['min_binary_slicelength'] * GLOBAL_DATA['sample_rate']\n",
        "    max_seg_len_label = GLOBAL_DATA['max_binary_slicelength'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    max_seg_len_raw = GLOBAL_DATA['max_binary_slicelength'] * GLOBAL_DATA['sample_rate']\n",
        "\n",
        "    label_order = [x[0] for x in groupby(y_sampled)]\n",
        "    label_change_idxs = np.where(y_sampled_np[:-1] != y_sampled_np[1:])[0]\n",
        "\n",
        "    start_raw_idx = 0\n",
        "    start_label_idx = 0\n",
        "    end_raw_idx = raw_data.size(0)\n",
        "    end_label_idx = len(y_sampled)\n",
        "    previous_bckg_len = 0\n",
        "\n",
        "    sliced_raws = []\n",
        "    sliced_labels = []\n",
        "    pre_bckg_lens_label = []\n",
        "    label_list_for_filename = []\n",
        "\n",
        "    for idx, label in enumerate(label_order):\n",
        "        # if last and the label is \"bckg\"\n",
        "        if (len(label_order) == idx+1) and (label == \"0\"):\n",
        "            sliced_raw_data = raw_data[start_raw_idx:].permute(1,0)\n",
        "            sliced_y1 = torch.Tensor(list(map(int,y_sampled[start_label_idx:]))).byte()\n",
        "\n",
        "            if sliced_y1.size(0) < min_seg_len_label:\n",
        "                continue\n",
        "            sliced_raws.append(sliced_raw_data)\n",
        "            sliced_labels.append(sliced_y1)\n",
        "            pre_bckg_lens_label.append(0)\n",
        "            label_list_for_filename.append(label)\n",
        "\n",
        "        # if not last and the label is \"bckg\"\n",
        "        elif (len(label_order) != idx+1) and (label == \"0\"):\n",
        "            end_raw_idx = (label_change_idxs[idx]+1) * GLOBAL_DATA['fsr_sr_ratio']\n",
        "            end_label_idx = label_change_idxs[idx]+1\n",
        "\n",
        "            sliced_raw_data = raw_data[start_raw_idx:end_raw_idx].permute(1,0)\n",
        "            sliced_y1 = torch.Tensor(list(map(int,y_sampled[start_label_idx:end_label_idx]))).byte()\n",
        "            previous_bckg_len = end_label_idx - start_label_idx\n",
        "\n",
        "            start_raw_idx = end_raw_idx\n",
        "            start_label_idx = end_label_idx\n",
        "            if sliced_y1.size(0) < min_seg_len_label:\n",
        "                continue\n",
        "\n",
        "            sliced_raws.append(sliced_raw_data)\n",
        "            sliced_labels.append(sliced_y1)\n",
        "            pre_bckg_lens_label.append(0)\n",
        "            label_list_for_filename.append(label)\n",
        "\n",
        "        # if the first and the label is \"seiz\" 1 ~ 8\n",
        "        elif (idx == 0) and (label != \"0\"):\n",
        "            end_raw_idx = (label_change_idxs[idx]+1) * GLOBAL_DATA['fsr_sr_ratio']\n",
        "            end_label_idx = label_change_idxs[idx]+1\n",
        "\n",
        "            if len(y_sampled)-end_label_idx > max_seg_len_after_seiz_label:\n",
        "                post_len_label = max_seg_len_after_seiz_label\n",
        "                post_len_raw = max_seg_len_after_seiz_raw\n",
        "            else:\n",
        "                post_len_label = len(y_sampled)-end_label_idx\n",
        "                post_len_raw = ((len(y_sampled)-end_label_idx) * GLOBAL_DATA['fsr_sr_ratio'])\n",
        "            post_ictal_end_label = end_label_idx + post_len_label\n",
        "            post_ictal_end_raw = end_raw_idx + post_len_raw\n",
        "\n",
        "            start_raw_idx = end_raw_idx\n",
        "            start_label_idx = end_label_idx\n",
        "            if len(y_sampled) < min_seg_len_label:\n",
        "                continue\n",
        "\n",
        "            sliced_raw_data = raw_data[:post_ictal_end_raw].permute(1,0)\n",
        "            sliced_y1 = torch.Tensor(list(map(int,y_sampled[:post_ictal_end_label]))).byte()\n",
        "\n",
        "            if sliced_y1.size(0) > max_seg_len_label:\n",
        "                sliced_y2 = sliced_y1[:max_seg_len_label]\n",
        "                sliced_raw_data2 = sliced_raw_data.permute(1,0)[:max_seg_len_raw].permute(1,0)\n",
        "                sliced_raws.append(sliced_raw_data2)\n",
        "                sliced_labels.append(sliced_y2)\n",
        "                pre_bckg_lens_label.append(0)\n",
        "                label_list_for_filename.append(label)\n",
        "            elif sliced_y1.size(0) >= min_seg_len_label:\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y1)\n",
        "                pre_bckg_lens_label.append(0)\n",
        "                label_list_for_filename.append(label)\n",
        "            else:\n",
        "                sliced_y2 = torch.Tensor(list(map(int,y_sampled[:min_seg_len_label]))).byte()\n",
        "                sliced_raw_data2 = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "                sliced_raws.append(sliced_raw_data2)\n",
        "                sliced_labels.append(sliced_y2)\n",
        "                pre_bckg_lens_label.append(0)\n",
        "                label_list_for_filename.append(label)\n",
        "\n",
        "        # the label is \"seiz\" 1 ~ 8\n",
        "        elif label != \"0\":\n",
        "            end_raw_idx = (label_change_idxs[idx]+1) * GLOBAL_DATA['fsr_sr_ratio']\n",
        "            end_label_idx = label_change_idxs[idx]+1\n",
        "\n",
        "            if len(y_sampled)-end_label_idx > max_seg_len_after_seiz_label:\n",
        "                post_len_label = max_seg_len_after_seiz_label\n",
        "                post_len_raw = max_seg_len_after_seiz_raw\n",
        "            else:\n",
        "                post_len_label = len(y_sampled)-end_label_idx\n",
        "                post_len_raw = ((len(y_sampled)-end_label_idx) * GLOBAL_DATA['fsr_sr_ratio'])\n",
        "            post_ictal_end_label = end_label_idx + post_len_label\n",
        "            post_ictal_end_raw = end_raw_idx + post_len_raw\n",
        "\n",
        "            if previous_bckg_len > max_seg_len_before_seiz_label:\n",
        "                pre_seiz_label_len = max_seg_len_before_seiz_label\n",
        "            else:\n",
        "                pre_seiz_label_len = previous_bckg_len\n",
        "            pre_seiz_raw_len = pre_seiz_label_len * GLOBAL_DATA['fsr_sr_ratio']\n",
        "\n",
        "            sample_len = post_ictal_end_label - (start_label_idx-pre_seiz_label_len)\n",
        "            if sample_len < min_seg_len_label:\n",
        "                post_ictal_end_label = start_label_idx - pre_seiz_label_len + min_seg_len_label\n",
        "                post_ictal_end_raw = start_raw_idx - pre_seiz_raw_len + min_seg_len_raw\n",
        "            if len(y_sampled) < post_ictal_end_label:\n",
        "                start_raw_idx = end_raw_idx\n",
        "                start_label_idx = end_label_idx\n",
        "                continue\n",
        "\n",
        "            sliced_raw_data = raw_data[start_raw_idx-pre_seiz_raw_len:post_ictal_end_raw].permute(1,0)\n",
        "            sliced_y1 = torch.Tensor(list(map(int,y_sampled[start_label_idx-pre_seiz_label_len:post_ictal_end_label]))).byte()\n",
        "\n",
        "            if sliced_y1.size(0) > max_seg_len_label:\n",
        "                sliced_y2 = sliced_y1[:max_seg_len_label]\n",
        "                sliced_raw_data2 = sliced_raw_data.permute(1,0)[:max_seg_len_raw].permute(1,0)\n",
        "                sliced_raws.append(sliced_raw_data2)\n",
        "                sliced_labels.append(sliced_y2)\n",
        "                pre_bckg_lens_label.append(pre_seiz_label_len)\n",
        "                label_list_for_filename.append(label)\n",
        "            # elif sliced_y1.size(0) >= min_seg_len_label:\n",
        "            else:\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y1)\n",
        "                pre_bckg_lens_label.append(pre_seiz_label_len)\n",
        "                label_list_for_filename.append(label)\n",
        "            start_raw_idx = end_raw_idx\n",
        "            start_label_idx = end_label_idx\n",
        "\n",
        "        else:\n",
        "            print(\"Error! Impossible!\")\n",
        "            exit(1)\n",
        "\n",
        "    for data_idx in range(len(sliced_raws)):\n",
        "        sliced_raw = sliced_raws[data_idx]\n",
        "        sliced_y = sliced_labels[data_idx]\n",
        "        sliced_y_map = list(map(int,sliced_y))\n",
        "\n",
        "        if GLOBAL_DATA['binary_target1'] is not None:\n",
        "            sliced_y2 = torch.Tensor([GLOBAL_DATA['binary_target1'][i] for i in sliced_y_map]).byte()\n",
        "        else:\n",
        "            sliced_y2 = None\n",
        "\n",
        "        if GLOBAL_DATA['binary_target2'] is not None:\n",
        "            sliced_y3 = torch.Tensor([GLOBAL_DATA['binary_target2'][i] for i in sliced_y_map]).byte()\n",
        "        else:\n",
        "            sliced_y3 = None\n",
        "\n",
        "        new_data['RAW_DATA'] = [sliced_raw]\n",
        "        new_data['LABEL1'] = [sliced_y]\n",
        "        new_data['LABEL2'] = [sliced_y2]\n",
        "        new_data['LABEL3'] = [sliced_y3]\n",
        "\n",
        "        prelabel_len = pre_bckg_lens_label[data_idx]\n",
        "        label = label_list_for_filename[data_idx]\n",
        "\n",
        "        with open(GLOBAL_DATA['data_file_directory'] + \"/{}_c{}_pre{}_len{}_label_{}.pkl\".format(data_file_name, str(data_idx), str(prelabel_len), str(len(sliced_y)), str(label)), 'wb') as _f:\n",
        "            pickle.dump(new_data, _f)\n",
        "        new_data = {}\n",
        "\n",
        "def generate_training_data_leadwise_tuh_train_final(file):\n",
        "    sample_rate = GLOBAL_DATA['sample_rate']    # EX) 200Hz\n",
        "    file_name = \".\".join(file.split(\".\")[:-1])  # EX) /content/tuh_eeg_seizuretrain/01_tcp_ar/072/00007235/s003_2010_11_20/00007235_s003_t000\n",
        "    data_file_name = file_name.split(\"/\")[-1]   # EX) 00007235_s003_t000\n",
        "    signals, signal_headers, header = highlevel.read_edf(file)\n",
        "    label_list_c = []\n",
        "    for idx, signal in enumerate(signals):\n",
        "        label_noref = signal_headers[idx]['label'].split(\"-\")[0]    # EX) EEG FP1-ref or EEG FP1-LE --> EEG FP1\n",
        "        label_list_c.append(label_noref)\n",
        "\n",
        "    ############################# part 1: labeling  ###############################\n",
        "    label_file = open(file_name + \".\" + GLOBAL_DATA['args.label_type'], 'r') # EX) 00007235_s003_t003.tse or 00007235_s003_t003.tse_bi\n",
        "    y = label_file.readlines()\n",
        "    y = list(y[2:])\n",
        "    y_labels = list(set([i.split(\" \")[2] for i in y]))\n",
        "    signal_sample_rate = int(signal_headers[0]['sample_rate'])\n",
        "    if sample_rate > signal_sample_rate:\n",
        "        return\n",
        "    if not all(elem in label_list_c for elem in GLOBAL_DATA['label_list']): # if one or more of ['EEG FP1', 'EEG FP2', ... doesn't exist\n",
        "        return\n",
        "    # if not any(elem in y_labels for elem in GLOBAL_DATA['disease_type']): # if non-patient exist\n",
        "    #     return\n",
        "    y_sampled = label_sampling_tuh(y, GLOBAL_DATA['feature_sample_rate'])\n",
        "\n",
        "    # check if seizure patient or non-seizure patient\n",
        "    patient_wise_dir = \"/\".join(file_name.split(\"/\")[:-2])\n",
        "    patient_id = file_name.split(\"/\")[-3]\n",
        "    edf_list = search_walk({'path': patient_wise_dir, 'extension': \".tse_bi\"})\n",
        "    patient_bool = False\n",
        "    for tse_bi_file in edf_list:\n",
        "        label_file = open(tse_bi_file, 'r') # EX) 00007235_s003_t003.tse or 00007235_s003_t003.tse_bi\n",
        "        y = label_file.readlines()\n",
        "        y = list(y[2:])\n",
        "        for line in y:\n",
        "            if len(line) > 5:\n",
        "                if line.split(\" \")[2] != 'bckg':\n",
        "                    patient_bool = True\n",
        "                    break\n",
        "        if patient_bool:\n",
        "            break\n",
        "\n",
        "    ############################# part 2: input data filtering #############################\n",
        "    signal_list = []\n",
        "    signal_label_list = []\n",
        "    signal_final_list_raw = []\n",
        "\n",
        "    for idx, signal in enumerate(signals):\n",
        "        label = signal_headers[idx]['label'].split(\"-\")[0]\n",
        "        if label not in GLOBAL_DATA['label_list']:\n",
        "            continue\n",
        "\n",
        "        if int(signal_headers[idx]['sample_rate']) > sample_rate:\n",
        "            secs = len(signal)/float(signal_sample_rate)\n",
        "            samps = int(secs*sample_rate)\n",
        "            x = sci_sig.resample(signal, samps)\n",
        "            signal_list.append(x)\n",
        "            signal_label_list.append(label)\n",
        "        else:\n",
        "            signal_list.append(signal)\n",
        "            signal_label_list.append(label)\n",
        "\n",
        "    if len(signal_label_list) != len(GLOBAL_DATA['label_list']):\n",
        "        print(\"Not enough labels: \", signal_label_list)\n",
        "        return\n",
        "\n",
        "    for lead_signal in GLOBAL_DATA['label_list']:\n",
        "        signal_final_list_raw.append(signal_list[signal_label_list.index(lead_signal)])\n",
        "\n",
        "    new_length = len(signal_final_list_raw[0]) * (float(GLOBAL_DATA['feature_sample_rate']) / GLOBAL_DATA['sample_rate'])\n",
        "\n",
        "    if len(y_sampled) > new_length:\n",
        "        y_sampled = y_sampled[:new_length]\n",
        "    elif len(y_sampled) < new_length:\n",
        "        diff = int(new_length - len(y_sampled))\n",
        "        y_sampled += y_sampled[-1] * diff\n",
        "\n",
        "    y_sampled_np = np.array(list(map(int,y_sampled)))\n",
        "    new_labels = []\n",
        "    new_labels_idxs = []\n",
        "\n",
        "    ############################# part 3: slicing for easy training  #############################\n",
        "    y_sampled = [\"0\" if l not in GLOBAL_DATA['selected_diseases'] else l for l in y_sampled]\n",
        "\n",
        "    if any(l in GLOBAL_DATA['selected_diseases'] for l in y_sampled):\n",
        "        y_sampled = [str(GLOBAL_DATA['target_dictionary'][int(l)]) if l in GLOBAL_DATA['selected_diseases'] else l for l in y_sampled]\n",
        "\n",
        "    # slice and save if training data\n",
        "    new_data = {}\n",
        "    raw_data = torch.Tensor(signal_final_list_raw).permute(1,0)\n",
        "    raw_data = raw_data.type(torch.float16)\n",
        "\n",
        "    min_seg_len_label = GLOBAL_DATA['min_binary_slicelength'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    min_seg_len_raw = GLOBAL_DATA['min_binary_slicelength'] * GLOBAL_DATA['sample_rate']\n",
        "    min_binary_edge_seiz_label = GLOBAL_DATA['min_binary_edge_seiz'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    min_binary_edge_seiz_raw = GLOBAL_DATA['min_binary_edge_seiz'] * GLOBAL_DATA['sample_rate']\n",
        "\n",
        "    label_order = [x[0] for x in groupby(y_sampled)]\n",
        "    label_change_idxs = np.where(y_sampled_np[:-1] != y_sampled_np[1:])[0]\n",
        "    label_change_idxs = np.append(label_change_idxs, np.array([len(y_sampled_np)-1]))\n",
        "\n",
        "    sliced_raws = []\n",
        "    sliced_labels = []\n",
        "    label_list_for_filename = []\n",
        "    if len(y_sampled) < min_seg_len_label:\n",
        "        return\n",
        "    else:\n",
        "        label_count = {}\n",
        "        y_sampled_2nd = list(y_sampled)\n",
        "        raw_data_2nd = raw_data\n",
        "        while len(y_sampled) >= min_seg_len_label:\n",
        "            is_at_middle = False\n",
        "            sliced_y = y_sampled[:min_seg_len_label]\n",
        "            labels = [x[0] for x in groupby(sliced_y)]\n",
        "\n",
        "            if len(labels) == 1 and \"0\" in labels:\n",
        "                y_sampled = y_sampled[min_seg_len_label:]\n",
        "                sliced_raw_data = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "                raw_data = raw_data[min_seg_len_raw:]\n",
        "                if patient_bool:\n",
        "                    label = \"0_patT\"\n",
        "                else:\n",
        "                    label = \"0_patF\"\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y)\n",
        "                label_list_for_filename.append(label)\n",
        "\n",
        "            elif len(labels) != 1 and (sliced_y[0] == '0') and (sliced_y[-1] != '0'):\n",
        "                temp_sliced_y = list(sliced_y)\n",
        "                temp_sliced_y.reverse()\n",
        "                boundary_seizlen = temp_sliced_y.index(\"0\") + 1\n",
        "                if boundary_seizlen < min_binary_edge_seiz_label:\n",
        "                    if len(y_sampled) > (min_seg_len_label + min_binary_edge_seiz_label):\n",
        "                        sliced_y = y_sampled[min_binary_edge_seiz_label:min_seg_len_label+min_binary_edge_seiz_label]\n",
        "                        sliced_raw_data = raw_data[min_binary_edge_seiz_raw:min_seg_len_raw+min_binary_edge_seiz_raw].permute(1,0)\n",
        "                    else:\n",
        "                        sliced_raw_data = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "                else:\n",
        "                    sliced_raw_data = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "\n",
        "                y_sampled = y_sampled[min_seg_len_label:]\n",
        "                raw_data = raw_data[min_seg_len_raw:]\n",
        "\n",
        "                label = str(max(list(map(int, labels))))\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y)\n",
        "\n",
        "                label = label + \"_beg\"\n",
        "                label_list_for_filename.append(label)\n",
        "                is_at_middle = True\n",
        "\n",
        "            elif (len(labels) != 1) and (sliced_y[0] != '0') and (sliced_y[-1] != '0'):\n",
        "                y_sampled = y_sampled[min_seg_len_label:]\n",
        "                sliced_raw_data = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "                raw_data = raw_data[min_seg_len_raw:]\n",
        "\n",
        "                label = str(max(list(map(int, labels))))\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y)\n",
        "\n",
        "                label = label + \"_whole\"\n",
        "                label_list_for_filename.append(label)\n",
        "                is_at_middle = True\n",
        "\n",
        "            elif (len(labels) == 1) and (sliced_y[0] != '0') and (sliced_y[-1] != '0'):\n",
        "                y_sampled = y_sampled[min_seg_len_label:]\n",
        "                sliced_raw_data = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "                raw_data = raw_data[min_seg_len_raw:]\n",
        "\n",
        "                label = str(max(list(map(int, labels))))\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y)\n",
        "\n",
        "                label = label + \"_middle\"\n",
        "                label_list_for_filename.append(label)\n",
        "                is_at_middle = True\n",
        "\n",
        "            elif len(labels) != 1 and (sliced_y[0] != '0') and (sliced_y[-1] == '0'):\n",
        "                y_sampled = y_sampled[min_seg_len_label:]\n",
        "                sliced_raw_data = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "                raw_data = raw_data[min_seg_len_raw:]\n",
        "\n",
        "                label = str(max(list(map(int, labels))))\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y)\n",
        "\n",
        "                label = label + \"_end\"\n",
        "                label_list_for_filename.append(label)\n",
        "\n",
        "            elif len(labels) != 1 and (sliced_y[0] == '0') and (sliced_y[-1] == '0'):\n",
        "                y_sampled = y_sampled[min_seg_len_label:]\n",
        "                sliced_raw_data = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "                raw_data = raw_data[min_seg_len_raw:]\n",
        "\n",
        "                label = str(max(list(map(int, labels))))\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y)\n",
        "\n",
        "                label = label + \"_whole\"\n",
        "                label_list_for_filename.append(label)\n",
        "\n",
        "            else:\n",
        "                print(\"unexpected case\")\n",
        "                exit(1)\n",
        "        if is_at_middle == True:\n",
        "            sliced_y = y_sampled_2nd[-min_seg_len_label:]\n",
        "            sliced_raw_data = raw_data_2nd[-min_seg_len_raw:].permute(1,0)\n",
        "\n",
        "            if sliced_y[-1] == '0':\n",
        "                label = str(max(list(map(int, labels))))\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y)\n",
        "\n",
        "                label = label + \"_end\"\n",
        "                label_list_for_filename.append(label)\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "    for data_idx in range(len(sliced_raws)):\n",
        "        sliced_raw = sliced_raws[data_idx]\n",
        "        sliced_y = sliced_labels[data_idx]\n",
        "        sliced_y_map = list(map(int,sliced_y))\n",
        "        sliced_y = torch.Tensor(sliced_y_map).byte()\n",
        "\n",
        "        if GLOBAL_DATA['binary_target1'] is not None:\n",
        "            sliced_y2 = torch.Tensor([GLOBAL_DATA['binary_target1'][i] for i in sliced_y_map]).byte()\n",
        "        else:\n",
        "            sliced_y2 = None\n",
        "\n",
        "        if GLOBAL_DATA['binary_target2'] is not None:\n",
        "            sliced_y3 = torch.Tensor([GLOBAL_DATA['binary_target2'][i] for i in sliced_y_map]).byte()\n",
        "        else:\n",
        "            sliced_y3 = None\n",
        "\n",
        "        new_data['RAW_DATA'] = [sliced_raw]\n",
        "        new_data['LABEL1'] = [sliced_y]\n",
        "        new_data['LABEL2'] = [sliced_y2]\n",
        "        new_data['LABEL3'] = [sliced_y3]\n",
        "\n",
        "        label = label_list_for_filename[data_idx]\n",
        "\n",
        "        with open(GLOBAL_DATA['data_file_directory'] + \"/{}_c{}_label_{}.pkl\".format(data_file_name, str(data_idx), str(label)), 'wb') as _f:\n",
        "            pickle.dump(new_data, _f)\n",
        "        new_data = {}\n",
        "\n",
        "def generate_training_data_leadwise_tuh_dev(file):\n",
        "    sample_rate = GLOBAL_DATA['sample_rate']    # EX) 200Hz\n",
        "    file_name = \".\".join(file.split(\".\")[:-1])  # EX) /content/tuh_eeg_seizuretrain/01_tcp_ar/072/00007235/s003_2010_11_20/00007235_s003_t000\n",
        "    data_file_name = file_name.split(\"/\")[-1]   # EX) 00007235_s003_t000\n",
        "    signals, signal_headers, header = highlevel.read_edf(file)\n",
        "    label_list_c = []\n",
        "    for idx, signal in enumerate(signals):\n",
        "        label_noref = signal_headers[idx]['label'].split(\"-\")[0]    # EX) EEG FP1-ref or EEG FP1-LE --> EEG FP1\n",
        "        label_list_c.append(label_noref)\n",
        "\n",
        "    ############################# part 1: labeling  ###############################\n",
        "    label_file = open(file_name + \".\" + GLOBAL_DATA['args.label_type'], 'r') # EX) 00007235_s003_t003.tse or 00007235_s003_t003.tse_bi\n",
        "    y = label_file.readlines()\n",
        "    y = list(y[2:])\n",
        "    y_labels = list(set([i.split(\" \")[2] for i in y]))\n",
        "    signal_sample_rate = int(signal_headers[0]['sample_rate'])\n",
        "    if sample_rate > signal_sample_rate:\n",
        "        return\n",
        "    if not all(elem in label_list_c for elem in GLOBAL_DATA['label_list']): # if one or more of ['EEG FP1', 'EEG FP2', ... doesn't exist\n",
        "        return\n",
        "    # if not any(elem in y_labels for elem in GLOBAL_DATA['disease_type']): # if non-patient exist\n",
        "    #     return\n",
        "    y_sampled = label_sampling_tuh(y, GLOBAL_DATA['feature_sample_rate'])\n",
        "\n",
        "    # check if seizure patient or non-seizure patient\n",
        "    patient_wise_dir = \"/\".join(file_name.split(\"/\")[:-2])\n",
        "    import os\n",
        "\n",
        "def search_walk(args):\n",
        "    path = args['path']\n",
        "    extension = args['extension']\n",
        "    file_list = []\n",
        "    for root, _, files in os.walk(path):\n",
        "        for file in files:\n",
        "            if file.endswith(extension):\n",
        "                file_list.append(os.path.join(root, file))\n",
        "    return file_list\n",
        "\n",
        "    edf_list = search_walk({'path': patient_wise_dir, 'extension': \".tse_bi\"})\n",
        "    patient_bool = False\n",
        "    for tse_bi_file in edf_list:\n",
        "        label_file = open(tse_bi_file, 'r') # EX) 00007235_s003_t003.tse or 00007235_s003_t003.tse_bi\n",
        "        y = label_file.readlines()\n",
        "        y = list(y[2:])\n",
        "        for line in y:\n",
        "            if len(line) > 5:\n",
        "                if line.split(\" \")[2] != 'bckg':\n",
        "                    patient_bool = True\n",
        "                    break\n",
        "        if patient_bool:\n",
        "            break\n",
        "\n",
        "    ############################# part 2: input data filtering #############################\n",
        "    signal_list = []\n",
        "    signal_label_list = []\n",
        "    signal_final_list_raw = []\n",
        "\n",
        "    for idx, signal in enumerate(signals):\n",
        "        label = signal_headers[idx]['label'].split(\"-\")[0]\n",
        "        if label not in GLOBAL_DATA['label_list']:\n",
        "            continue\n",
        "\n",
        "        if int(signal_headers[idx]['sample_rate']) > sample_rate:\n",
        "            secs = len(signal)/float(signal_sample_rate)\n",
        "            samps = int(secs*sample_rate)\n",
        "            x = sci_sig.resample(signal, samps)\n",
        "            signal_list.append(x)\n",
        "            signal_label_list.append(label)\n",
        "        else:\n",
        "            signal_list.append(signal)\n",
        "            signal_label_list.append(label)\n",
        "\n",
        "    if len(signal_label_list) != len(GLOBAL_DATA['label_list']):\n",
        "        print(\"Not enough labels: \", signal_label_list)\n",
        "        return\n",
        "\n",
        "    for lead_signal in GLOBAL_DATA['label_list']:\n",
        "        signal_final_list_raw.append(signal_list[signal_label_list.index(lead_signal)])\n",
        "\n",
        "    new_length = len(signal_final_list_raw[0]) * (float(GLOBAL_DATA['feature_sample_rate']) / GLOBAL_DATA['sample_rate'])\n",
        "\n",
        "    if len(y_sampled) > new_length:\n",
        "        y_sampled = y_sampled[:new_length]\n",
        "    elif len(y_sampled) < new_length:\n",
        "        diff = int(new_length - len(y_sampled))\n",
        "        y_sampled += y_sampled[-1] * diff\n",
        "\n",
        "    y_sampled_np = np.array(list(map(int,y_sampled)))\n",
        "    new_labels = []\n",
        "    new_labels_idxs = []\n",
        "\n",
        "    ############################# part 3: slicing for easy training  #############################\n",
        "    y_sampled = [\"0\" if l not in GLOBAL_DATA['selected_diseases'] else l for l in y_sampled]\n",
        "\n",
        "    if any(l in GLOBAL_DATA['selected_diseases'] for l in y_sampled):\n",
        "        y_sampled = [str(GLOBAL_DATA['target_dictionary'][int(l)]) if l in GLOBAL_DATA['selected_diseases'] else l for l in y_sampled]\n",
        "\n",
        "    # slice and save if training data\n",
        "    new_data = {}\n",
        "    raw_data = torch.Tensor(signal_final_list_raw).permute(1,0)\n",
        "    raw_data = raw_data.type(torch.float16)\n",
        "\n",
        "    # max_seg_len_before_seiz_label = GLOBAL_DATA['max_bckg_before_slicelength'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    # max_seg_len_before_seiz_raw = GLOBAL_DATA['max_bckg_before_slicelength'] * GLOBAL_DATA['sample_rate']\n",
        "    # min_end_margin_label = args.slice_end_margin_length * GLOBAL_DATA['feature_sample_rate']\n",
        "    # min_end_margin_raw = args.slice_end_margin_length * GLOBAL_DATA['sample_rate']\n",
        "\n",
        "    min_seg_len_label = GLOBAL_DATA['min_binary_slicelength'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    min_seg_len_raw = GLOBAL_DATA['min_binary_slicelength'] * GLOBAL_DATA['sample_rate']\n",
        "    # max_seg_len_label = GLOBAL_DATA['max_binary_slicelength'] * GLOBAL_DATA['feature_sample_rate']\n",
        "    # max_seg_len_raw = GLOBAL_DATA['max_binary_slicelength'] * GLOBAL_DATA['sample_rate']\n",
        "\n",
        "    sliced_raws = []\n",
        "    sliced_labels = []\n",
        "    label_list_for_filename = []\n",
        "\n",
        "    if len(y_sampled) < min_seg_len_label:\n",
        "        return\n",
        "    else:\n",
        "        label_count = {}\n",
        "        while len(y_sampled) >= min_seg_len_label:\n",
        "            one_left_slice = False\n",
        "            sliced_y = y_sampled[:min_seg_len_label]\n",
        "\n",
        "            if (sliced_y[-1] == '0'):\n",
        "                sliced_raw_data = raw_data[:min_seg_len_raw].permute(1,0)\n",
        "                raw_data = raw_data[min_seg_len_raw:]\n",
        "                y_sampled = y_sampled[min_seg_len_label:]\n",
        "\n",
        "                labels = [x[0] for x in groupby(sliced_y)]\n",
        "                if (len(labels) == 1) and (labels[0] == '0'):\n",
        "                    label = \"0\"\n",
        "                else:\n",
        "                    label = (\"\".join(labels)).replace(\"0\", \"\")[0]\n",
        "                sliced_raws.append(sliced_raw_data)\n",
        "                sliced_labels.append(sliced_y)\n",
        "                label_list_for_filename.append(label)\n",
        "\n",
        "            else:\n",
        "                if '0' in y_sampled[min_seg_len_label:]:\n",
        "                    end_1 = y_sampled[min_seg_len_label:].index('0')\n",
        "                    temp_y_sampled = list(y_sampled[min_seg_len_label+end_1:])\n",
        "                    temp_y_sampled_order = [x[0] for x in groupby(temp_y_sampled)]\n",
        "\n",
        "                    if len(list(set(temp_y_sampled))) == 1:\n",
        "                        end_2 = len(temp_y_sampled)\n",
        "                        one_left_slice = True\n",
        "                    else:\n",
        "                        end_2 = temp_y_sampled.index(temp_y_sampled_order[1])\n",
        "\n",
        "                    if end_2 >= min_end_margin_label:\n",
        "                        temp_sec = random.randint(1,args.slice_end_margin_length)\n",
        "                        temp_seg_len_label = int(min_seg_len_label + (temp_sec * args.feature_sample_rate) + end_1)\n",
        "                        temp_seg_len_raw = int(min_seg_len_raw + (temp_sec * args.samplerate) + (end_1 * GLOBAL_DATA['fsr_sr_ratio']))\n",
        "                    else:\n",
        "                        if one_left_slice:\n",
        "                            temp_label = end_2\n",
        "                        else:\n",
        "                            temp_label = end_2 // 2\n",
        "\n",
        "                        temp_seg_len_label = int(min_seg_len_label + temp_label + end_1)\n",
        "                        temp_seg_len_raw = int(min_seg_len_raw + (temp_label * GLOBAL_DATA['fsr_sr_ratio']) + (end_1 * GLOBAL_DATA['fsr_sr_ratio']))\n",
        "\n",
        "                    sliced_y = y_sampled[:temp_seg_len_label]\n",
        "                    sliced_raw_data = raw_data[:temp_seg_len_raw].permute(1,0)\n",
        "                    raw_data = raw_data[temp_seg_len_raw:]\n",
        "                    y_sampled = y_sampled[temp_seg_len_label:]\n",
        "\n",
        "                    labels = [x[0] for x in groupby(sliced_y)]\n",
        "                    if (len(labels) == 1) and (labels[0] == '0'):\n",
        "                        label = \"0\"\n",
        "                    else:\n",
        "                        label = (\"\".join(labels)).replace(\"0\", \"\")[0]\n",
        "                    sliced_raws.append(sliced_raw_data)\n",
        "                    sliced_labels.append(sliced_y)\n",
        "                    label_list_for_filename.append(label)\n",
        "                else:\n",
        "                    sliced_y = y_sampled[:]\n",
        "                    sliced_raw_data = raw_data[:].permute(1,0)\n",
        "                    raw_data = []\n",
        "                    y_sampled = []\n",
        "\n",
        "                    labels = [x[0] for x in groupby(sliced_y)]\n",
        "                    if (len(labels) == 1) and (labels[0] == '0'):\n",
        "                        label = \"0\"\n",
        "                    else:\n",
        "                        label = (\"\".join(labels)).replace(\"0\", \"\")[0]\n",
        "                    sliced_raws.append(sliced_raw_data)\n",
        "                    sliced_labels.append(sliced_y)\n",
        "                    label_list_for_filename.append(label)\n",
        "\n",
        "    for data_idx in range(len(sliced_raws)):\n",
        "        sliced_raw = sliced_raws[data_idx]\n",
        "        sliced_y = sliced_labels[data_idx]\n",
        "        sliced_y_map = list(map(int,sliced_y))\n",
        "\n",
        "        if GLOBAL_DATA['binary_target1'] is not None:\n",
        "            sliced_y2 = torch.Tensor([GLOBAL_DATA['binary_target1'][i] for i in sliced_y_map]).byte()\n",
        "        else:\n",
        "            sliced_y2 = None\n",
        "\n",
        "        if GLOBAL_DATA['binary_target2'] is not None:\n",
        "            sliced_y3 = torch.Tensor([GLOBAL_DATA['binary_target2'][i] for i in sliced_y_map]).byte()\n",
        "        else:\n",
        "            sliced_y3 = None\n",
        "\n",
        "        new_data['RAW_DATA'] = [sliced_raw]\n",
        "        new_data['LABEL1'] = [sliced_y]\n",
        "        new_data['LABEL2'] = [sliced_y2]\n",
        "        new_data['LABEL3'] = [sliced_y3]\n",
        "\n",
        "        label = label_list_for_filename[data_idx]\n",
        "\n",
        "        with open(GLOBAL_DATA['data_file_directory'] + \"/{}_c{}_len{}_label_{}.pkl\".format(data_file_name, str(data_idx), str(len(sliced_y)), str(label)), 'wb') as _f:\n",
        "            pickle.dump(new_data, _f)\n",
        "        new_data = {}\n",
        "\n",
        "\n",
        "    from argparse import Namespace\n",
        "\n",
        "def main(args):\n",
        "    save_directory = args.save_directory\n",
        "    data_type = args.data_type\n",
        "    dataset = args.dataset\n",
        "    label_type = args.label_type\n",
        "    sample_rate = args.sample_rate\n",
        "    cpu_num = args.cpu_num\n",
        "    feature_type = args.feature_type\n",
        "    feature_sample_rate = args.feature_sample_rate\n",
        "    task_type = args.task_type\n",
        "\n",
        "\n",
        "\n",
        "    # Add your real code here\n",
        "\n",
        "# ðŸ‘‡ Create a manual args object\n",
        "from argparse import Namespace\n",
        "args = Namespace(\n",
        "    save_directory=\"/content/tuh_eeg_seizure/edf\",\n",
        "    dataset=\"tuh\",\n",
        "    task_type=\"binary\",\n",
        "    data_type=\"train\",\n",
        "    label_type=\"tse\",\n",
        "    sample_rate=250,\n",
        "    cpu_num=2,\n",
        "    feature_type=\"default\",\n",
        "    feature_sample_rate=1\n",
        "\n",
        ")\n",
        "data_file_directory = f\"{args.save_directory}/dataset-{args.dataset}_task-{args.task_type}_datatype-{args.data_type}_v6\"\n",
        "\n",
        "\n",
        "labels = ['EEG FP1', 'EEG FP2', 'EEG F3', 'EEG F4', 'EEG F7', 'EEG F8',\n",
        "                    'EEG C3', 'EEG C4', 'EEG CZ', 'EEG T3', 'EEG T4',\n",
        "                    'EEG P3', 'EEG P4', 'EEG O1', 'EEG O2', 'EEG T5', 'EEG T6', 'EEG PZ', 'EEG FZ']\n",
        "eeg_data_directory = \"/content/tuh_eeg_seizure{}\".format(args.data_type)\n",
        "    # eeg_data_directory = \"/mnt/aitrics_ext/ext01/shared/edf/tuh_final/{}\".format(data_type)\n",
        "if args.label_type == \"tse\":\n",
        "    disease_labels = {\n",
        "        'bckg': 0, 'cpsz': 1, 'mysz': 2, 'gnsz': 3,\n",
        "        'fnsz': 4, 'tnsz': 5, 'tcsz': 6, 'spsz': 7, 'absz': 8\n",
        "    }\n",
        "elif args.label_type == \"tse_bi\":\n",
        "    disease_labels = {\n",
        "        'bckg': 0, 'seiz': 1\n",
        "    }\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported args.label_type: {args.label_type}\")\n",
        "\n",
        "disease_labels_inv = {v: k for k, v in disease_labels.items()}\n",
        "\n",
        "\n",
        "edf_list1 = search_walk({'path': eeg_data_directory, 'extension': \".edf\"})\n",
        "edf_list2 = search_walk({'path': eeg_data_directory, 'extension': \".EDF\"})\n",
        "if edf_list2:\n",
        "        edf_list = edf_list1 + edf_list2\n",
        "else:\n",
        "        edf_list = edf_list1\n",
        "if os.path.isdir(data_file_directory):\n",
        "        os.system(\"rm -rf {}\".format(data_file_directory))\n",
        "os.system(\"mkdir {}\".format(data_file_directory))\n",
        "\n",
        "GLOBAL_DATA['label_list'] = labels # 'EEG FP1', 'EEG FP2', 'EEG F3', ...\n",
        "GLOBAL_DATA['disease_labels'] = disease_labels #  {'bckg': 0, 'cpsz': 1, 'mysz': 2, ...\n",
        "GLOBAL_DATA['disease_labels_inv'] = disease_labels_inv #  {0:'bckg', 1:'cpsz', 2:'mysz', ...\n",
        "GLOBAL_DATA['data_file_directory'] = data_file_directory\n",
        "GLOBAL_DATA['args.label_type'] = args.label_type # \"tse_bi\" ...\n",
        "GLOBAL_DATA['args.feature_type'] = args.feature_type\n",
        "GLOBAL_DATA['args.feature_sample_rate'] = args.feature_sample_rate\n",
        "GLOBAL_DATA['args.sample_rate'] = args.sample_rate\n",
        "GLOBAL_DATA['fsr_sr_ratio'] = (args.sample_rate // args.feature_sample_rate)\n",
        "GLOBAL_DATA['min_binary_slicelength'] =  getattr(args, 'min_binary_slicelength',30)\n",
        "GLOBAL_DATA['min_binary_edge_seiz'] = getattr(args, 'min_binary_edge_seiz',3)\n",
        "\n",
        "target_dictionary = {0:0}\n",
        "selected_diseases = []\n",
        "for idx, i in enumerate(getattr(args, 'disease_type', [])):\n",
        "        selected_diseases.append(str(disease_labels[i]))\n",
        "        target_dictionary[disease_labels[i]] = idx + 1\n",
        "\n",
        "GLOBAL_DATA['disease_type'] =getattr(args, 'disease_type',['gnsz', 'fnsz', 'spsz', 'cpsz', 'absz', 'tnsz', 'tcsz', 'mysz'])\n",
        "GLOBAL_DATA['target_dictionary'] = target_dictionary # {0: 0, 4: 1, 5: 2, 8: 3, 2: 4, 9: 5, 6: 6, 7: 7, 3: 8}\n",
        "GLOBAL_DATA['selected_diseases'] = selected_diseases # ['4', '5', '8', '2', '9', '6', '7', '3']\n",
        "GLOBAL_DATA['binary_target1'] = getattr(args, 'binary_target1', {0:0, 1:1, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1, 8:1})\n",
        "GLOBAL_DATA['binary_target2'] = getattr(args, 'binary_target2', {0:0, 1:1, 2:2, 3:2, 4:2, 5:1, 6:3, 7:4, 8:5})\n",
        "\n",
        "print(\"########## Preprocessor Setting Information ##########\")\n",
        "print(\"Number of EDF files: \", len(edf_list))\n",
        "for i in GLOBAL_DATA:\n",
        "        print(\"{}: {}\".format(i, GLOBAL_DATA[i]))\n",
        "with open(data_file_directory + '/preprocess_info.infopkl', 'wb') as pkl:\n",
        "        pickle.dump(GLOBAL_DATA, pkl, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "print(\"################ Preprocess begins... ################\\n\")\n",
        "\n",
        "if (args.task_type == \"binary\") and (args.data_type == \"train\"):\n",
        "  if not hasattr(args, 'cpu_num') or args.cpu_num < 1:\n",
        "    args.cpu_num = os.cpu_count() or 1\n",
        "\n",
        "    run_multi_process(generate_training_data_leadwise_tuh_train_final, edf_list, n_processes=args.cpu_num)\n",
        "\n",
        "elif (args.task_type == \"binary\") and (args.data_type == \"dev\"):\n",
        "    cpu_num = max(1, getattr(args, 'cpu_num', os.cpu_count() or 1))\n",
        "    run_multi_process(generate_training_data_leadwise_tuh_train_final, edf_list, n_processes=cpu_num)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # make sure all edf file name different!!! if not, additional coding is necessary\n",
        "   # make sure all edf file names are different!!! if not, additional coding is necessary\n",
        "    import sys\n",
        "# Remove Jupyter/Colab's auto-added -f argument\n",
        "    sys.argv = [sys.argv[0]] + [arg for arg in sys.argv[1:] if not arg.startswith(\"-f\") and not arg.endswith(\".json\")]\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--seed', '-sd', type=int, default=1004,\n",
        "                        help='Random seed number')\n",
        "    parser.add_argument('--samplerate', '-sr', type=int, default=200,\n",
        "                        help='Sample Rate')\n",
        "    parser.add_argument('--save_directory', '-sp', type=str,\n",
        "                        help='Path to save data')\n",
        "    parser.add_argument('--label_type', '-lt', type=str,\n",
        "                        default='tse',\n",
        "                        help='tse_bi = global with binary label, tse = global with various labels, cae = severance CAE seizure label.')\n",
        "    parser.add_argument('--cpu_num', '-cn', type=int,\n",
        "                        default=32,\n",
        "                        help='select number of available cpus')\n",
        "    parser.add_argument('--feature_type', '-ft', type=str,\n",
        "                        default=['rawsignal'])\n",
        "    parser.add_argument('--sample_rate', type=int,\n",
        "                        default=200,\n",
        "                        help='Sampling rate of the data')\n",
        "\n",
        "    parser.add_argument('--feature_sample_rate', '-fsr', type=int,\n",
        "                        default=50,\n",
        "                        help='select features sample rate')\n",
        "    parser.add_argument('--dataset', '-st', type=str,\n",
        "                        default='tuh',\n",
        "                        choices=['tuh'])\n",
        "    parser.add_argument('--data_type', '-dt', type=str,\n",
        "                        default='train',\n",
        "                        choices=['train', 'dev'])\n",
        "    parser.add_argument('--task_type', '-tt', type=str,\n",
        "                        default='binary',\n",
        "                        choices=['anomaly', 'multiclassification', 'binary'])\n",
        "\n",
        "\n",
        "\n",
        "    ##### Target Grouping #####\n",
        "    parser.add_argument('--disease_type', type=list, default=['gnsz', 'fnsz', 'spsz', 'cpsz', 'absz', 'tnsz', 'tcsz', 'mysz'], choices=['gnsz', 'fnsz', 'spsz', 'cpsz', 'absz', 'tnsz', 'tcsz', 'mysz'])\n",
        "\n",
        "    ### for binary detector ###\n",
        "    # key numbers represent index of --disease_type + 1  ### -1 is \"not being used\"\n",
        "    parser.add_argument('--binary_target1', type=dict, default={0:0, 1:1, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1, 8:1})\n",
        "    parser.add_argument('--binary_target2', type=dict, default={0:0, 1:1, 2:2, 3:2, 4:2, 5:1, 6:3, 7:4, 8:5})\n",
        "    parser.add_argument('--min_binary_slicelength', type=int, default=30)\n",
        "    parser.add_argument('--min_binary_edge_seiz', type=int, default=3)\n",
        "    args = parser.parse_args()\n",
        "    main(args)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAml9dBOmfZa"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5oI5J5kDiZu"
      },
      "outputs": [],
      "source": [
        "    import torch\n",
        "    import torch.nn as nn\n",
        "\n",
        "    class CNN2D_LSTM_V1(nn.Module):\n",
        "      def __init__(self, args, device):\n",
        "        super(CNN2D_LSTM_V1, self).__init__()\n",
        "        self.conv = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.lstm = nn.LSTM(input_size=16 * 32 * 32, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(64, 2)\n",
        "\n",
        "      def forward(self, x):\n",
        "        batch_size, seq_len, c, h, w = x.shape\n",
        "        x = x.view(batch_size * seq_len, c, h, w)\n",
        "        x = self.pool(torch.relu(self.conv(x)))\n",
        "        x = x.view(batch_size, seq_len, -1)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1])\n",
        "        return x\n",
        "    model = CNN2D_LSTM_V1(args, device).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uEXMsFGIpxf"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import math\n",
        "\n",
        "class CosineAnnealingWarmUpSingle(_LRScheduler):\n",
        "    def __init__(self, optimizer, max_lr, epochs, steps_per_epoch, pct_start=0.3, div_factor=25.0, final_div_factor=1e4, last_epoch=-1, verbose=False):\n",
        "        self.max_lr = max_lr\n",
        "        self.total_steps = epochs * steps_per_epoch\n",
        "        self.warmup_steps = int(self.total_steps * pct_start)\n",
        "        self.div_factor = div_factor\n",
        "        self.final_div_factor = final_div_factor\n",
        "        super().__init__(optimizer, last_epoch, verbose)\n",
        "\n",
        "    def get_lr(self):\n",
        "        step = self.last_epoch\n",
        "        if step < self.warmup_steps:\n",
        "            # linear warmup\n",
        "            warmup_factor = step / max(1, self.warmup_steps)\n",
        "            lrs = [base_lr + warmup_factor * (self.max_lr - base_lr) for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            # cosine annealing\n",
        "            progress = (step - self.warmup_steps) / max(1, self.total_steps - self.warmup_steps)\n",
        "            cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))\n",
        "            lrs = [self.max_lr * cosine_decay for _ in self.base_lrs]\n",
        "        return lrs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqaRPn5kNCCM"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "\n",
        "def load_eeg_data(file_path):\n",
        "    raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
        "    data = raw.get_data()  # shape: (channels, time)\n",
        "    return torch.tensor(data, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOWH3gDQOo3U"
      },
      "outputs": [],
      "source": [
        "def __getitem__(self, index):\n",
        "    ...\n",
        "    return train_x, train_y, seq_len, target_len  # â† maybe just 4 items\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV6ZIbnTUNI7"
      },
      "outputs": [],
      "source": [
        "class Detector_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, file_list, args):\n",
        "        self.file_list = file_list\n",
        "        self.args = args\n",
        "        # load/process your data here\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Training Model"
      ],
      "metadata": {
        "id": "YXk5laI62zn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DwikMk1BgTU"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) 2022, Kwanhyung Lee, Hyewon Jeong, Seyun Kim AITRICS. All rights reserved.\n",
        "#\n",
        "# Licensed under the MIT License;\n",
        "# you may not use this file except in compliance with the License.\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "import random\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io.wavfile import write\n",
        "from itertools import groupby\n",
        "import math\n",
        "import time\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "from torchinfo import summary\n",
        "\n",
        "from builder.utils.lars import LARC\n",
        "from control.config import args\n",
        "\n",
        "from builder.data.data_preprocess import get_data_preprocessed\n",
        "# from builder.data.data_preprocess_temp1 import get_data_preprocessed\n",
        "from builder.models import get_detector_model, grad_cam\n",
        "from builder.utils.logger import Logger\n",
        "from builder.utils.utils import set_seeds, set_devices\n",
        "from builder.utils.cosine_annealing_with_warmup import CosineAnnealingWarmUpRestarts\n",
        "from builder.utils.cosine_annealing_with_warmupSingle import CosineAnnealingWarmUpSingle\n",
        "from builder.trainer import get_trainer\n",
        "from builder.trainer import *\n",
        "from torch.utils.data import DataLoader\n",
        "class CustomLogger(Logger):\n",
        "    def __init__(self, args):\n",
        "        super().__init__(args)\n",
        "        self.y_true_multi = []\n",
        "        self.y_pred_multi = []\n",
        "logger = CustomLogger(args)\n",
        "logger.y_true_multi = []\n",
        "logger.y_pred_multi = []\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "list_of_test_results_per_seed = []\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import math\n",
        "\n",
        "class CosineAnnealingWarmUpSingle(_LRScheduler):\n",
        "    def __init__(self, optimizer, max_lr, epochs, steps_per_epoch,\n",
        "                 pct_start=0.3, div_factor=25.0, final_div_factor=1e4, last_epoch=-1, verbose=False):\n",
        "        self.max_lr = max_lr\n",
        "        self.total_steps = epochs * steps_per_epoch\n",
        "        self.warmup_steps = int(self.total_steps * pct_start)\n",
        "        self.div_factor = div_factor\n",
        "        self.final_div_factor = final_div_factor\n",
        "        self.min_lr = max_lr / final_div_factor\n",
        "        self.base_lrs = [max_lr / div_factor for _ in optimizer.param_groups]\n",
        "        super().__init__(optimizer, last_epoch, verbose)\n",
        "\n",
        "    def get_lr(self):\n",
        "        step = self.last_epoch + 1  # because PyTorch calls this before stepping\n",
        "        if step < self.warmup_steps:\n",
        "            warmup_factor = step / self.warmup_steps\n",
        "            return [\n",
        "                base_lr + warmup_factor * (self.max_lr - base_lr)\n",
        "                for base_lr in self.base_lrs\n",
        "            ]\n",
        "        else:\n",
        "            decay_step = step - self.warmup_steps\n",
        "            total_decay_steps = self.total_steps - self.warmup_steps\n",
        "            cosine_decay = 0.5 * (1 + math.cos(math.pi * decay_step / total_decay_steps))\n",
        "            return [\n",
        "                self.min_lr + (self.max_lr - self.min_lr) * cosine_decay\n",
        "                for _ in self.optimizer.param_groups\n",
        "            ]\n",
        "\n",
        "\n",
        "# define result class\n",
        "class ResultsSaver:\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.results = []\n",
        "\n",
        "    def results_all_seeds(self, test_results):\n",
        "        # Implement your logic to save/process results from all seeds\n",
        "        self.results.append(test_results)\n",
        "        print(f\"Saved results from seed {self.args.seed}: {test_results}\")\n",
        "\n",
        "# Implement your functions to return instances of this class\n",
        "def experiment_results_validation(args):\n",
        "    return ResultsSaver(args)\n",
        "\n",
        "def experiment_results(args):\n",
        "    return ResultsSaver(args)\n",
        "\n",
        "# Initialize your results savers\n",
        "save_valid_results = experiment_results_validation(args)\n",
        "save_test_results = experiment_results(args)\n",
        "\n",
        "# Your existing loop\n",
        "for seed_num in args.seed_list:\n",
        "    args.seed = seed_num\n",
        "    set_seeds(args)\n",
        "    device = set_devices(args)\n",
        "    print(device)\n",
        "    logger = Logger(args)\n",
        "    logger.evaluator.best_auc = 0\n",
        "\n",
        "\n",
        "\n",
        "    save_valid_results.results_all_seeds(logger.test_results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import mne  # For actual EDF file loading\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import mne\n",
        "import glob\n",
        "import random\n",
        "from torch import nn\n",
        "\n",
        "class Detector_Dataset(Dataset):\n",
        "    def __init__(self, args, edf_files, transform=None):\n",
        "        self.edf_files = edf_files\n",
        "        self.args = args\n",
        "        self.transform = transform\n",
        "        self.required_channels = 12\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.edf_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.edf_files[idx]\n",
        "        try:\n",
        "            # 1. Load raw EEG data\n",
        "            raw_data = self._load_edf(file_path)  # [12, 256]\n",
        "\n",
        "            # 2. Create all 5 required components as torch tensors\n",
        "            v = torch.tensor(self._create_time_features(raw_data), dtype=torch.float32)\n",
        "            w = torch.tensor(self._create_freq_features(raw_data), dtype=torch.float32)\n",
        "            x = torch.tensor(self._create_raw_features(raw_data), dtype=torch.float32)\n",
        "            y = torch.tensor(self._get_label(file_path), dtype=torch.long)\n",
        "            z = torch.tensor(self._get_metadata(raw_data), dtype=torch.float32)\n",
        "\n",
        "            if self.transform:\n",
        "                x = self.transform(x)\n",
        "\n",
        "            return v, w, x, y, z  # This must be properly indented inside __getitem__\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {str(e)}\")\n",
        "            dummy = torch.zeros((12, 1, 3), dtype=torch.float32)\n",
        "            return dummy, dummy, dummy, torch.tensor(0, dtype=torch.long), dummy\n",
        "\n",
        "    # Rest of your methods (_load_edf, _create_time_features, etc.) go here\n",
        "\n",
        "    def _load_edf(self, file_path):\n",
        "        \"\"\"Load EDF and return raw data [12, 256]\"\"\"\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
        "            raw.pick(range(self.required_channels))\n",
        "            return raw.get_data()  # [channels, timepoints]\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"EDF loading failed: {str(e)}\")\n",
        "\n",
        "    def _create_time_features(self, data):\n",
        "        \"\"\"Create time-domain features [12, 1, 3]\"\"\"\n",
        "        features = np.zeros((12, 1, 3))\n",
        "        features[:, 0, 0] = data.mean(axis=1)\n",
        "        features[:, 0, 1] = data.std(axis=1)\n",
        "        features[:, 0, 2] = np.median(data, axis=1)\n",
        "        return features\n",
        "\n",
        "    def _create_freq_features(self, data):\n",
        "        \"\"\"Create frequency-domain features [12, 1, 3]\"\"\"\n",
        "        psd = np.abs(np.fft.fft(data)[:, :3])\n",
        "        return psd.reshape(12, 1, 3)\n",
        "\n",
        "    def _create_raw_features(self, data):\n",
        "        \"\"\"Create raw signal features [12, 1, 3]\"\"\"\n",
        "        window = data.shape[1] // 3\n",
        "        features = np.zeros((12, 1, 3))\n",
        "        for i in range(3):\n",
        "            features[:, 0, i] = data[:, i*window:(i+1)*window].mean(axis=1)\n",
        "        return features\n",
        "\n",
        "    def _get_label(self, file_path):\n",
        "        return 1 if \"seizure\" in str(file_path).lower() else 0\n",
        "\n",
        "    def _get_metadata(self, data):\n",
        "        \"\"\"Create additional metadata [12, 1, 3]\"\"\"\n",
        "        metadata = np.zeros((12, 1, 3))\n",
        "        metadata[:, 0, 0] = data.max(axis=1) - data.min(axis=1)\n",
        "        metadata[:, 0, 1] = np.percentile(data, 75, axis=1)\n",
        "        metadata[:, 0, 2] = np.percentile(data, 25, axis=1)\n",
        "        return metadata\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Convert numpy arrays to tensors and stack\"\"\"\n",
        "    try:\n",
        "        v = torch.stack([item[0] for item in batch])\n",
        "        w = torch.stack([item[1] for item in batch])\n",
        "        x = torch.stack([item[2] for item in batch])\n",
        "        y = torch.stack([item[3] for item in batch])\n",
        "        z = torch.stack([item[4] for item in batch])\n",
        "        return v, w, x, y, z\n",
        "    except Exception as e:\n",
        "        print(f\"Collate error: {e}\")\n",
        "        raise\n",
        "\n",
        "def get_data_preprocessed(args):\n",
        "    file_list = glob.glob(\"/content/tuh_eeg_seizure/edf/**/*.edf\", recursive=True)\n",
        "    if not file_list:\n",
        "        raise ValueError(\"No EDF files found!\")\n",
        "\n",
        "    random.shuffle(file_list)\n",
        "    split_idx = [int(0.7*len(file_list)), int(0.85*len(file_list))]\n",
        "    train_files, dev_files, eval_files = np.split(file_list, split_idx)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = Detector_Dataset(args, train_files)\n",
        "    dev_dataset = Detector_Dataset(args, dev_files)\n",
        "    eval_dataset = Detector_Dataset(args, eval_files)\n",
        "\n",
        "    # Calculate safe number of workers\n",
        "    num_workers = min(4, (os.cpu_count() or 1)//2)\n",
        "\n",
        "    # Create loaders\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=args.batch_size,\n",
        "      shuffle=True,\n",
        "      collate_fn=collate_fn,\n",
        "      num_workers=0 if os.name == 'nt' else min(4, os.cpu_count()//2),  # Windows needs num_workers=0\n",
        "      pin_memory=torch.cuda.is_available(),\n",
        "      persistent_workers=False  # Add this line\n",
        ")\n",
        "\n",
        "    dev_loader = DataLoader(\n",
        "        dev_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    eval_loader = DataLoader(\n",
        "        eval_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    # Add this at the end of your training script:\n",
        "    import gc\n",
        "    gc.collect()  # Helps clean up multiprocessing resources\n",
        "\n",
        "\n",
        "    # Verify first batch\n",
        "    print(\"\\nDataLoader Sanity Check:\")\n",
        "    sample = next(iter(train_loader))\n",
        "    for i, tensor in enumerate(sample):\n",
        "        print(f\"Item {i}: shape={tensor.shape}, dtype={tensor.dtype}\")\n",
        "\n",
        "    return train_loader, dev_loader, eval_loader\n",
        "\n",
        "# Main execution\n",
        "for seed_num in args.seed_list:\n",
        "    args.seed = seed_num\n",
        "    set_seeds(args)\n",
        "    device = set_devices(args)\n",
        "    logger = Logger(args)\n",
        "    logger.evaluator.best_auc = 0\n",
        "\n",
        "    # Load Data\n",
        "    try:\n",
        "        train_loader, dev_loader, eval_loader = get_data_preprocessed(args)\n",
        "        print(f\"Train batches: {len(train_loader)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        continue  # Skip to next seed if data loading fails\n",
        "\n",
        "    # Rest of your training loop...\n",
        "    one_epoch_iter_num = len(train_loader)  # Now this will work\n",
        "    print(\"Iterations per epoch: \", one_epoch_iter_num)\n",
        "\n",
        "class CNN2D_LSTM_V1(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.bidirectional = True\n",
        "\n",
        "        # Adjusted CNN architecture to handle input shape [batch, 12, 1, 3]\n",
        "        self.conv_block = nn.Sequential(\n",
        "            # Input: [batch, channels=12, height=1, width=3]\n",
        "            nn.Conv2d(in_channels=12, out_channels=32, kernel_size=(1,1)),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=(1,1)),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=64,  # Must match CNN output channels\n",
        "            hidden_size=128,\n",
        "            batch_first=True,\n",
        "            bidirectional=self.bidirectional\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        lstm_output_size = 128 * 2 if self.bidirectional else 128\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, v, w, x, y, z):\n",
        "        # 1. Combine features along width dimension\n",
        "        # Input shapes: [batch, 12, 1, 3] for v,w,x,z\n",
        "        x_combined = torch.cat([v, w, x, z], dim=-1)  # [batch, 12, 1, 12]\n",
        "\n",
        "        # 2. Permute for CNN: [batch, channels, height, width]\n",
        "        x = x_combined.permute(0, 3, 1, 2)  # [batch, 12, 12, 1] -> WRONG\n",
        "        # Correct approach:\n",
        "        x = x_combined.permute(0, 1, 2, 3)  # Maintain [batch, 12, 1, 12]\n",
        "\n",
        "        # 3. CNN processing\n",
        "        x = self.conv_block(x)  # [batch, 64, 1, 12]\n",
        "\n",
        "        # 4. Prepare for LSTM: [batch, seq_len, features]\n",
        "        x = x.squeeze(2).permute(0, 2, 1)  # [batch, 12, 64]\n",
        "\n",
        "        # 5. LSTM processing\n",
        "        x, _ = self.lstm(x)  # [batch, 12, 256] (if bidirectional)\n",
        "\n",
        "        # 6. Get final state\n",
        "        if self.bidirectional:\n",
        "            x = torch.cat([x[:, -1, :128], x[:, 0, 128:]], dim=-1)\n",
        "        else:\n",
        "            x = x[:, -1, :]\n",
        "\n",
        "        return self.fc(x)\n",
        "\n",
        "# 2. Initialize device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 3. Initialize model\n",
        "model = CNN2D_LSTM_V1(args).to(device)\n",
        "print(\"\\nModel Architecture:\")\n",
        "print(model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dev_per_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "if args.checkpoint:\n",
        "    if args.last:\n",
        "        ckpt_path = args.dir_result + '/' + args.project_name + '/ckpts/last_{}.pth'.format(str(seed_num))\n",
        "    elif args.best:\n",
        "        ckpt_path = args.dir_result + '/' + args.project_name + '/ckpts/best_{}.pth'.format(str(seed_num))\n",
        "\n",
        "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    logger.best_auc = checkpoint['score']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    del checkpoint\n",
        "else:\n",
        "    logger.best_auc = 0\n",
        "    start_epoch = 1\n",
        "\n",
        "\n",
        "if args.optim == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr_init, weight_decay=args.weight_decay)\n",
        "elif args.optim == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=args.lr_init, momentum=args.momentum, weight_decay=args.weight_decay)\n",
        "elif args.optim == 'adamw':\n",
        "        optimizer = optim.AdamW(model.parameters(), lr = args.lr_init, weight_decay=args.weight_decay)\n",
        "elif args.optim == 'adam_lars':\n",
        "        optimizer = optim.Adam(model.parameters(), lr = args.lr_init, weight_decay=args.weight_decay)\n",
        "        optimizer = LARC(optimizer=optimizer, eps=1e-8, trust_coefficient=0.001)\n",
        "elif args.optim == 'sgd_lars':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=args.lr_init, momentum=args.momentum, weight_decay=args.weight_decay)\n",
        "        optimizer = LARC(optimizer=optimizer, eps=1e-8, trust_coefficient=0.001)\n",
        "elif args.optim == 'adamw_lars':\n",
        "        optimizer = optim.AdamW(model.parameters(), lr = args.lr_init, weight_decay=args.weight_decay)\n",
        "        optimizer = LARC(optimizer=optimizer, eps=1e-8, trust_coefficient=0.001)\n",
        "\n",
        "one_epoch_iter_num = len(train_loader)\n",
        "print(\"Iterations per epoch: \", one_epoch_iter_num)\n",
        "iteration_num = args.epochs * one_epoch_iter_num\n",
        "\n",
        "# Learning Rate Scheduler Setup\n",
        "if args.lr_scheduler == \"CosineAnnealing\":\n",
        "    # Enhanced CosineAnnealingWarmUpRestarts with better defaults\n",
        "    scheduler = CosineAnnealingWarmUpRestarts(\n",
        "        optimizer,\n",
        "        T_0=10 * one_epoch_iter_num,      # 10 epoch cycles (prevents LR from getting too small)\n",
        "        T_mult=1,                         # Keep cycle length constant\n",
        "        eta_max=args.lr_init * 5,         # Peak LR = 5x initial LR\n",
        "        T_up=2 * one_epoch_iter_num,      # 2 epoch warmup\n",
        "        gamma=0.7                         # Gentle decay factor\n",
        "    )\n",
        "    print(f\"Using CosineAnnealingWarmUpRestarts: \"\n",
        "          f\"{args.epochs} epochs, {one_epoch_iter_num} iters/epoch, \"\n",
        "          f\"peak LR={args.lr_init * 5:.1e}\")\n",
        "\n",
        "elif args.lr_scheduler == \"OneCycle\":\n",
        "    # Turbo-charged OneCycleLR with automatic batch scaling\n",
        "    base_lr = args.lr_init * math.sqrt(args.batch_size / 32)  # Scale LR by sqrt(batch_size/32)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=base_lr * 10,              # 10x base LR (automatically scaled)\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=args.epochs,\n",
        "        pct_start=0.3,                    # 30% of iterations spent increasing LR\n",
        "        div_factor=25,                     # Starts from max_lr/25\n",
        "        final_div_factor=1e4,              # Ends at max_lr/1e4\n",
        "        anneal_strategy='cos',             # Smoother annealing\n",
        "        cycle_momentum=True if isinstance(optimizer, optim.SGD) else False\n",
        "    )\n",
        "    print(f\"Using OneCycleLR: max_lr={base_lr * 10:.1e} \"\n",
        "          f\"(batch_size scaled from base {base_lr:.1e})\")\n",
        "\n",
        "# Add this to your training loop to monitor LR (after optimizer.step()):\n",
        "current_lr = scheduler.get_last_lr()[0]\n",
        "if batch_idx % 50 == 0:\n",
        "    print(f\"Epoch {epoch} Batch {batch_idx}: LR = {current_lr:.2e}\")\n",
        "    if args.lr_scheduler == \"OneCycle\":\n",
        "        # For OneCycle only - track momentum if using SGD\n",
        "        if isinstance(optimizer, optim.SGD):\n",
        "            momentum_group = [pg['momentum'] for pg in optimizer.param_groups]\n",
        "            print(f\"Current momentum: {momentum_group[0]:.3f}\")\n",
        "\n",
        "model.train()\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Prevents overconfidence\n",
        "  # Ensure reduction='mean' (default)\n",
        "epoch_losses = []\n",
        "for epoch in range(start_epoch, args.epochs + 1):\n",
        "    logger.loss = 0.0  # Reset epoch logger\n",
        "    epoch_losses = []   # Reset per-epoch losses\n",
        "    for batch_idx, (v, w, x, y, z) in enumerate(train_loader):\n",
        "        try:\n",
        "            # Verify shapes\n",
        "            print(f\"Batch shapes - v:{v.shape}, w:{w.shape}, x:{x.shape}, y:{y.shape}, z:{z.shape}\")\n",
        "\n",
        "            # Move to device\n",
        "            v = v.to(device, non_blocking=True)\n",
        "            w = w.to(device, non_blocking=True)\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            z = z.to(device, non_blocking=True)\n",
        "\n",
        "            # Verify target dtype\n",
        "            assert y.dtype == torch.long, f\"Target y must be long dtype, got {y.dtype}\"\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            outputs = model(v, w, x, y, z)\n",
        "\n",
        "            # Verify output shape\n",
        "            assert outputs.shape[0] == y.shape[0], \"Batch size mismatch\"\n",
        "            assert outputs.shape[1] == 2, \"Output should have shape [batch, 2]\"\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, y)\n",
        "            print(f\"Batch {batch_idx} loss: {loss.item():.4f}\")\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            if epoch < 5:  # First 5 epochs\n",
        "              for g in optimizer.param_groups:\n",
        "                g['lr'] = args.lr_init * (epoch / 5)\n",
        "            # Gradient clipping\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # --- Second part of your processing ---\n",
        "            # Using v,w,x,y,z instead of train_x, train_y to maintain consistency\n",
        "            train_x, train_y = x, y  # Assuming x is your input and y is target\n",
        "\n",
        "            # Data validation before processing\n",
        "            if train_x is None:\n",
        "                raise ValueError(\"Batch features are None\")\n",
        "            if not isinstance(train_x, torch.Tensor):\n",
        "                raise ValueError(f\"Expected tensor, got {type(train_x)}\")\n",
        "            if torch.isnan(train_x).any():\n",
        "                raise ValueError(\"NaN values detected in input features\")\n",
        "\n",
        "            # Move to device (already done above)\n",
        "            # Forward pass (already done above)\n",
        "            # Loss calculation (already done above)\n",
        "\n",
        "            # Gradient validation\n",
        "            if batch_idx % 50 == 0:\n",
        "                grad_norms = [p.grad.norm().item() for p in model.parameters() if p.grad is not None]\n",
        "                if not grad_norms:\n",
        "                    print(\"Warning: No gradients detected!\")\n",
        "                else:\n",
        "                    avg_grad = sum(grad_norms)/len(grad_norms)\n",
        "                    if avg_grad < 1e-6:\n",
        "                        print(\"Warning: Vanishing gradients detected!\")\n",
        "\n",
        "            # Logging\n",
        "            logger.loss += loss.item()\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Epoch: {epoch} | Batch: {batch_idx}/{len(train_loader)} | Loss: {loss.item():.4f}')\n",
        "\n",
        "            # Periodic output validation\n",
        "            if batch_idx % 20 == 0:\n",
        "                with torch.no_grad():\n",
        "                    sample_output = model(v[:1], w[:1], x[:1], y[:1], z[:1])\n",
        "                    print(f\"Output range: [{sample_output.min():.4f}, {sample_output.max():.4f}]\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError in batch {batch_idx}:\")\n",
        "            print(f\"Exception: {str(e)}\")\n",
        "            print(\"Batch contents:\")\n",
        "            # Using the actual variables we have (v,w,x,y,z)\n",
        "            for i, item in enumerate([v, w, x, y, z]):\n",
        "                print(f\"Item {i}: Type={type(item)}\")\n",
        "                if torch.is_tensor(item):\n",
        "                    print(f\"Shape: {item.shape}\")\n",
        "            continue\n",
        "\n",
        "    avg_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else float('nan')\n",
        "    print(f\"Epoch {epoch} complete | Average Loss: {avg_loss}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# End of epoch processing\n",
        "avg_epoch_loss = np.mean(epoch_losses)\n",
        "print(f'\\nEpoch {epoch} complete | Average Loss: {avg_epoch_loss:.4f}')\n",
        "pbar.update(1)\n",
        "ps_per_epoch = one_epoch_iter_num\n",
        "div_factor = math.sqrt(args.batch_size)\n",
        "\n",
        "save_valid_results.results_all_seeds(logger.test_results)\n",
        "del model\n",
        "\n",
        "\n",
        "\n",
        "print(\"#################################################\")\n",
        "print(\"################# Test Begins ###################\")\n",
        "print(\"#################################################\")\n",
        "logger = Logger(args)\n",
        "\n",
        "# Set up evaluation\n",
        "class Evaluator:\n",
        "    def __init__(self, args):\n",
        "        # initialization code\n",
        "        pass\n",
        "evaluator = Evaluator(args)\n",
        "names = [args.project_name]\n",
        "average_speed_over = 10\n",
        "time_taken = 0\n",
        "num_windows = 30 - args.window_size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for name in names:\n",
        "\n",
        "\n",
        "  if args.last:\n",
        "       ckpt_path = os.path.join(args.dir_result, name, \"ckpts\", f\"last_{args.seed}.pth\")\n",
        "  elif args.best:\n",
        "       ckpt_path = os.path.join(args.dir_result, name, \"ckpts\", f\"best_{args.seed}.pth\")\n",
        "  else:\n",
        "       ckpt_path = os.path.join(args.dir_result, name, \"ckpts\", \"best.pth\")  # fallback default\n",
        "\n",
        "\n",
        "# Load checkpoint if exists\n",
        "if os.path.exists(ckpt_path):\n",
        "    print(f\"Loading checkpoint from {ckpt_path}\")\n",
        "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "    # Load model state\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "\n",
        "    # Resume training from next epoch\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "    # Optional: Load other training states if available\n",
        "    if 'optimizer' in checkpoint:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    if 'scheduler' in checkpoint:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    if 'best_auc' in checkpoint:\n",
        "        logger.best_auc = checkpoint['best_auc']\n",
        "\n",
        "    print(f\"Resuming training from epoch {start_epoch}\")\n",
        "else:\n",
        "    print(\"No checkpoint found - training from scratch\")\n",
        "\n",
        "\n",
        "    # initialize test step\n",
        "def evaluate(model, eval_loader, device, logger):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for v, w, x, y, z in eval_loader:\n",
        "            v, w, x, y, z = v.to(device), w.to(device), x.to(device), y.to(device), z.to(device)\n",
        "\n",
        "            outputs = model(v, w, x, y, z)\n",
        "            preds = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "    auc = roc_auc_score(all_labels, [p[1] for p in all_preds])\n",
        "    apr = average_precision_score(all_labels, [p[1] for p in all_preds])\n",
        "    f1 = f1_score(all_labels, np.argmax(all_preds, axis=1))\n",
        "\n",
        "    return auc, apr, f1\n",
        "\n",
        "logger.writer.close()\n",
        "\n",
        "auc_list = []\n",
        "apr_list = []\n",
        "f1_list = []\n",
        "tpr_list = []\n",
        "tnr_list = []\n",
        "os.system(\"echo  \\'#######################################\\'\")\n",
        "os.system(\"echo  \\'##### Final test results per seed #####\\'\")\n",
        "os.system(\"echo  \\'#######################################\\'\")\n",
        "for result, tpr, tnr in list_of_test_results_per_seed:\n",
        "    os.system(\"echo  \\'seed_case:{} -- auc: {}, apr: {}, f1 _score: {}, tpr: {}, tnr: {}\\'\".format(str(result[0]), str(result[1]), str(result[2]), str(result[3]), str(tpr), str(tnr)))\n",
        "    auc_list.append(result[1])\n",
        "    apr_list.append(result[2])\n",
        "    f1_list.append(result[3])\n",
        "    tpr_list.append(tpr)\n",
        "    tnr_list.append(tnr)\n",
        "os.system(\"echo  \\'Total average -- auc: {}, apr: {}, f1_score: {}, tnr: {}, tpr: {}\\'\".format(str(np.mean(auc_list)), str(np.mean(apr_list)), str(np.mean(f1_list)), str(np.mean(tpr_list)), str(np.mean(tnr_list))))\n",
        "os.system(\"echo  \\'Total std -- auc: {}, apr: {}, f1_score: {}, tnr: {}, tpr: {}\\'\".format(str(np.std(auc_list)), str(np.std(apr_list)), str(np.std(f1_list)), str(np.std(tpr_list)), str(np.std(tnr_list))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Optimization"
      ],
      "metadata": {
        "id": "a7vnscOj7Gan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add these before optimize_for_tinyml()\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import prune\n",
        "\n",
        "class Tiny_CNN2D_LSTM(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(12, 16, kernel_size=(1,1)),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU6(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Conv2d(16, 32, kernel_size=(1,1)),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU6(),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(input_size=32, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU6(),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, v, w, x, y, z):\n",
        "        x_combined = torch.cat([v, w, x, z], dim=-1)\n",
        "        x = x_combined.permute(0, 3, 1, 2)\n",
        "        x = self.conv_block(x)\n",
        "        x = x.squeeze(2).permute(0, 2, 1)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        return self.fc(x)\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    def __init__(self, temperature=2.0):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def forward(self, student_output, teacher_output, labels):\n",
        "        soft_loss = self.kl_loss(\n",
        "            F.log_softmax(student_output/self.temperature, dim=1),\n",
        "            F.softmax(teacher_output/self.temperature, dim=1)\n",
        "        ) * (self.temperature ** 2)\n",
        "        hard_loss = F.cross_entropy(student_output, labels)\n",
        "        return 0.7 * soft_loss + 0.3 * hard_loss\n",
        "\n",
        "def prepare_for_quantization(model):\n",
        "    model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "    return torch.quantization.prepare_qat(model.train())\n",
        "\n",
        "def quantize_model(model):\n",
        "    model.eval()\n",
        "    return torch.quantization.convert(model)\n",
        "\n",
        "def apply_pruning(model, amount=0.2):\n",
        "    parameters_to_prune = [\n",
        "        (module, 'weight')\n",
        "        for module in model.modules()\n",
        "        if isinstance(module, (nn.Linear, nn.Conv2d))\n",
        "    ]\n",
        "    prune.global_unstructured(\n",
        "        parameters_to_prune,\n",
        "        pruning_method=prune.L1Unstructured,\n",
        "        amount=amount\n",
        "    )\n",
        "    for module, _ in parameters_to_prune:\n",
        "        prune.remove(module, 'weight')\n",
        "    return model\n",
        "\n",
        "def train_with_distillation(student, teacher, train_loader, epochs=10):\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "    criterion = DistillationLoss()\n",
        "    optimizer = optim.AdamW(student.parameters(), lr=1e-4)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for v, w, x, y, z in train_loader:\n",
        "            v, w, x, y, z = v.to(device), w.to(device), x.to(device), y.to(device), z.to(device)\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(v, w, x, y, z)\n",
        "            student_logits = student(v, w, x, y, z)\n",
        "            loss = criterion(student_logits, teacher_logits, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "kHQ04HkJ7IdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_for_tinyml(args, train_loader, dev_loader):\n",
        "    # 1. Create original and tiny models\n",
        "    original_model = CNN2D_LSTM_V1(args).to(device)\n",
        "    tiny_model = Tiny_CNN2D_LSTM(args).to(device)\n",
        "\n",
        "    # 2. Train original model (if not already trained)\n",
        "    if not args.checkpoint:\n",
        "        train_model(original_model, train_loader, dev_loader)\n",
        "\n",
        "    # 3. Apply knowledge distillation\n",
        "    print(\"Applying knowledge distillation...\")\n",
        "    train_with_distillation(tiny_model, original_model, train_loader)\n",
        "\n",
        "    # 4. Prepare for quantization aware training\n",
        "    print(\"Preparing for quantization...\")\n",
        "    tiny_model = prepare_for_quantization(tiny_model)\n",
        "\n",
        "    # 5. Fine-tune with QAT\n",
        "    print(\"Quantization aware training...\")\n",
        "    train_model(tiny_model, train_loader, dev_loader, epochs=5)\n",
        "\n",
        "    # 6. Apply pruning\n",
        "    print(\"Applying pruning...\")\n",
        "    tiny_model = apply_pruning(tiny_model)\n",
        "\n",
        "    # 7. Final quantization\n",
        "    print(\"Final quantization...\")\n",
        "    tiny_model = quantize_model(tiny_model)\n",
        "\n",
        "    # 8. Evaluate\n",
        "    print(\"Evaluating optimized model...\")\n",
        "    eval_results = evaluate(tiny_model, dev_loader, device)\n",
        "\n",
        "    # 9. Save for deployment\n",
        "    torch.save(tiny_model.state_dict(), 'tinyml_eeg_model.pth')\n",
        "\n",
        "    # 10. Convert to ONNX/TFLite for edge deployment\n",
        "    dummy_input = (torch.randn(1, 12, 1, 3), torch.randn(1, 12, 1, 3),\n",
        "                   torch.randn(1, 12, 1, 3), torch.zeros(1, dtype=torch.long),\n",
        "                   torch.randn(1, 12, 1, 3))\n",
        "    torch.onnx.export(tiny_model, dummy_input, 'tinyml_eeg_model.onnx')\n",
        "\n",
        "    return tiny_model, eval_results"
      ],
      "metadata": {
        "id": "ETrPHUtY7TWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if args.run_tinyml_optimization:\n",
        "    optimized_model, results = optimize_for_tinyml(args, train_loader, dev_loader)\n",
        "    print(f\"Optimized model results: {results}\")"
      ],
      "metadata": {
        "id": "vmyCmOTp7YJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test Data"
      ],
      "metadata": {
        "id": "3e2AXWpq238K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8lnFerSPkuQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define your 12-channel model\n",
        "class CNN2D_LSTM_V1(nn.Module):\n",
        "    def __init__(self, args, device):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(12, 32, kernel_size=(1,3), padding=(0,1))\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(1,3), padding=(0,1))\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(input_size=32, hidden_size=128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, args.output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Verify input shape\n",
        "        if x.size(1) != 12:\n",
        "            raise ValueError(f\"Expected 12 input channels, got {x.size(1)}. Input shape: {x.shape}\")\n",
        "\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = x.squeeze(2).permute(0, 2, 1)  # [batch, seq_len, features]\n",
        "        x, _ = self.lstm(x)\n",
        "        return self.fc(x[:, -1, :])  # Return last timestep\n",
        "\n",
        "# Initialize device and model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN2D_LSTM_V1(args, device).to(device)\n",
        "\n",
        "# Load data\n",
        "train_loader, val_loader, test_loader, len_train_dir, len_val_dir, len_test_dir = get_data_preprocessed(args)\n",
        "\n",
        "# Load checkpoint\n",
        "if args.last:\n",
        "    ckpt_path = os.path.join(args.dir_result, args.project_name, 'ckpts', 'last.pth')\n",
        "elif args.best:\n",
        "    ckpt_path = os.path.join(args.dir_result, args.project_name, 'ckpts', 'best_0.pth')\n",
        "\n",
        "if not os.path.exists(ckpt_path):\n",
        "    print(f\"Checkpoint not found at {ckpt_path}\")\n",
        "    exit(1)\n",
        "\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "model.load_state_dict(ckpt['model'])\n",
        "print(f\"Loaded model from {ckpt_path}\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
        "            # Handle different batch formats\n",
        "            if isinstance(batch, dict):\n",
        "                x = batch['data']\n",
        "                y = batch['label']\n",
        "            else:\n",
        "                x, y = batch[0], batch[1]\n",
        "\n",
        "            # Prepare input\n",
        "            x = x.to(device).float()\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Ensure correct input shape [batch, 12, 1, time_steps]\n",
        "            if x.dim() == 3:\n",
        "                x = x.unsqueeze(2)  # Add height dimension if missing\n",
        "\n",
        "            # Handle single-channel input by repeating\n",
        "            if x.size(1) == 1:\n",
        "                x = x.repeat(1, 12, 1, 1)\n",
        "            elif x.size(1) != 12:\n",
        "                raise ValueError(f\"Expected 1 or 12 input channels, got {x.size(1)}\")\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(x)\n",
        "            preds = torch.sigmoid(outputs) if args.task_type == \"binary\" else torch.softmax(outputs, dim=1)\n",
        "\n",
        "            y_true.append(y.cpu().numpy())\n",
        "            y_pred.append(preds.cpu().numpy())\n",
        "\n",
        "    return np.concatenate(y_true), np.concatenate(y_pred)\n",
        "\n",
        "# Run evaluation\n",
        "print(\"\\nStarting evaluation...\")\n",
        "y_true, y_pred = evaluate(model, test_loader, device)\n",
        "\n",
        "# Calculate metrics\n",
        "if args.task_type == \"binary\":\n",
        "    from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
        "\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "    y_pred_class = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred_class)\n",
        "    f1 = f1_score(y_true, y_pred_class)\n",
        "\n",
        "    print(\"\\nTest Results:\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "else:\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    y_pred_class = np.argmax(y_pred, axis=1)\n",
        "    acc = accuracy_score(y_true, y_pred_class)\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(\"\\nEvaluation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Seizure Test"
      ],
      "metadata": {
        "id": "6ok3GHmj3GL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp6jVQ6BRs2p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import find_peaks\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from builder.data.data_preprocess import get_data_preprocessed\n",
        "from builder.models import get_detector_model\n",
        "from builder.utils.metrics import Evaluator\n",
        "from builder.utils.logger import Logger\n",
        "from builder.utils.utils import set_seeds, set_devices\n",
        "\n",
        "# Configure environment\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class SeizureEvaluator:\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.device = set_devices(args)\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "        self.logger = Logger(args)\n",
        "\n",
        "    def calc_hf(self, ref, hyp):\n",
        "        \"\"\"Calculate hit and false alarm fractions between two events\"\"\"\n",
        "        start_r, stop_r = ref\n",
        "        start_h, stop_h = hyp\n",
        "\n",
        "        ref_dur = stop_r - start_r\n",
        "        hyp_dur = stop_h - start_h\n",
        "        hit = fa = 0.0\n",
        "\n",
        "        if start_h <= start_r and stop_h <= stop_r:  # Pre-prediction\n",
        "            hit = (stop_h - start_r) / ref_dur\n",
        "            fa = min((start_r - start_h) / ref_dur, 1.0)\n",
        "        elif start_h >= start_r and stop_h >= stop_r:  # Post-prediction\n",
        "            hit = (stop_r - start_h) / ref_dur\n",
        "            fa = min((stop_h - stop_r) / ref_dur, 1.0)\n",
        "        elif start_h < start_r and stop_h > stop_r:  # Over-prediction\n",
        "            hit = 1.0\n",
        "            fa = min(((stop_h - stop_r) + (start_r - start_h)) / ref_dur, 1.0)\n",
        "        else:  # Under-prediction\n",
        "            hit = hyp_dur / ref_dur\n",
        "\n",
        "        return hit, fa\n",
        "\n",
        "    def detect_events(self, signal, threshold=0.5):\n",
        "        \"\"\"Detect seizure events in signal using threshold\"\"\"\n",
        "        signal = np.array(signal)\n",
        "        padded = np.concatenate([[0], signal, [0]])\n",
        "        diff = np.diff(padded)\n",
        "        starts = np.where(diff > threshold)[0]\n",
        "        ends = np.where(diff < -threshold)[0]\n",
        "        return list(zip(starts, ends))\n",
        "\n",
        "    def evaluate_segments(self, model, test_loader):\n",
        "        \"\"\"Main evaluation function\"\"\"\n",
        "        model.eval()\n",
        "        all_refs = []\n",
        "        all_hyps = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "                x, y, seq_lens, target_lens, _, _ = batch\n",
        "                x = x.to(self.device)\n",
        "\n",
        "                # Process in sliding windows\n",
        "                for i in range(0, x.size(1), self.args.window_size):\n",
        "                    x_window = x[:, i:i+self.args.window_size]\n",
        "                    if x_window.size(1) < self.args.min_segment_length:\n",
        "                        continue\n",
        "\n",
        "                    outputs = model(x_window)\n",
        "                    probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "                    # Store results\n",
        "                    all_hyps.extend(probs[:, 1].tolist())\n",
        "                    all_refs.extend(y[:, i:i+self.args.window_size].cpu().numpy().tolist())\n",
        "\n",
        "        return self.calculate_metrics(all_refs, all_hyps)\n",
        "\n",
        "    def calculate_metrics(self, refs, hyps):\n",
        "        \"\"\"Calculate all evaluation metrics\"\"\"\n",
        "        # Convert to numpy arrays\n",
        "        refs = np.array(refs)\n",
        "        hyps = np.array(hyps)\n",
        "\n",
        "        # 1. Calculate traditional metrics\n",
        "        precision, recall, thresholds = precision_recall_curve(refs, hyps)\n",
        "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "        best_idx = np.argmax(f1_scores)\n",
        "\n",
        "        # 2. Calculate event-based metrics\n",
        "        ref_events = self.detect_events(refs, threshold=0.5)\n",
        "        hyp_events = self.detect_events(hyps, threshold=thresholds[best_idx])\n",
        "\n",
        "        # Calculate OVLP and TAES metrics\n",
        "        ovlp_metrics = self.calculate_ovlp(ref_events, hyp_events)\n",
        "        taes_metrics = self.calculate_taes(ref_events, hyp_events)\n",
        "\n",
        "        # Calculate latencies\n",
        "        latency_metrics = self.calculate_latencies(ref_events, hyp_events)\n",
        "\n",
        "        return {\n",
        "            'precision': precision[best_idx],\n",
        "            'recall': recall[best_idx],\n",
        "            'f1': f1_scores[best_idx],\n",
        "            'threshold': thresholds[best_idx],\n",
        "            'ovlp': ovlp_metrics,\n",
        "            'taes': taes_metrics,\n",
        "            'latency': latency_metrics\n",
        "        }\n",
        "\n",
        "    def run_evaluation(self):\n",
        "        \"\"\"Complete evaluation pipeline\"\"\"\n",
        "        set_seeds(self.args)\n",
        "\n",
        "        # Load data and model\n",
        "        train_loader, val_loader, test_loader, _, _, _ = get_data_preprocessed(self.args)\n",
        "        model = get_detector_model(self.args)(self.args, self.device).to(self.device)\n",
        "\n",
        "        # Load checkpoint\n",
        "        ckpt_path = os.path.join(\n",
        "            self.args.dir_result,\n",
        "            self.args.project_name,\n",
        "            'ckpts',\n",
        "            f\"best_{self.args.seed}.pth\" if self.args.best else \"last.pth\"\n",
        "        )\n",
        "\n",
        "        if os.path.exists(ckpt_path):\n",
        "            ckpt = torch.load(ckpt_path, map_location=self.device)\n",
        "            model.load_state_dict(ckpt['model'])\n",
        "            print(f\"Loaded model from {ckpt_path}\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Checkpoint not found at {ckpt_path}\")\n",
        "\n",
        "        # Run evaluation\n",
        "        results = self.evaluate_segments(model, test_loader)\n",
        "\n",
        "        # Print and return results\n",
        "        print(\"\\nEvaluation Results:\")\n",
        "        print(f\"Precision: {results['precision']:.4f}\")\n",
        "        print(f\"Recall: {results['recall']:.4f}\")\n",
        "        print(f\"F1 Score: {results['f1']:.4f}\")\n",
        "        print(f\"Optimal Threshold: {results['threshold']:.4f}\")\n",
        "\n",
        "        print(\"\\nOVLP Metrics:\")\n",
        "        print(f\"Sensitivity: {results['ovlp']['tpr']:.4f}\")\n",
        "        print(f\"Specificity: {results['ovlp']['tnr']:.4f}\")\n",
        "\n",
        "        print(\"\\nTAES Metrics:\")\n",
        "        print(f\"Sensitivity: {results['taes']['tpr']:.4f}\")\n",
        "        print(f\"Specificity: {results['taes']['tnr']:.4f}\")\n",
        "\n",
        "        print(\"\\nLatency Metrics:\")\n",
        "        print(f\"Average Latency: {results['latency']['avg']:.2f}s\")\n",
        "        print(f\"Detection Rate: {results['latency']['detection_rate']:.2f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize from config\n",
        "    from control.config import args\n",
        "\n",
        "    # Run evaluation\n",
        "    evaluator = SeizureEvaluator(args)\n",
        "    results = evaluator.run_evaluation()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1unvrpDr7vNSPopVsaO51oBW8G_zhhVZu",
      "authorship_tag": "ABX9TyMh4cdAXIJlNNLlWM7cp5Qk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}